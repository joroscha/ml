{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"../Data/Matrix_Apr10.xlsx\", sheetname='train')\n",
    "test = pd.read_excel(\"../Data/Matrix_Apr10.xlsx\", sheetname='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3 categories\n",
    "train['growth'] = np.where(train['Y'] <= np.mean(train.Y) - np.std(train.Y), \"NEGATIVE\", np.where(train['Y'] >= np.mean(train.Y) + np.std(train.Y), \"HIGH_GROWTH\", \"NORMAL_GROWTH\"))\n",
    "test['growth'] = np.where(test['Y'] <= np.mean(train.Y) - np.std(train.Y), \"NEGATIVE\", np.where(test['Y'] >= np.mean(train.Y) + np.std(train.Y), \"HIGH_GROWTH\", \"NORMAL_GROWTH\"))\n",
    "\n",
    "#2 categories evenly distributed\n",
    "# train['growth'] = np.where(train['Y'] <= np.mean(train.Y), \"BELOW AVERAGE\", \"ABOVE AVERAGE\")\n",
    "# test['growth'] = np.where(test['Y'] <= np.mean(train.Y), \"BELOW AVERAGE\", \"ABOVE AVERAGE\")\n",
    "\n",
    "#2 categories high/not high growth\n",
    "# train['growth'] = np.where(train['Y'] <= np.mean(train.Y) + np.std(train.Y), \"NOT HIGH GROWTH\", \"HIGH GROWTH\")\n",
    "# test['growth'] = np.where(test['Y'] <= np.mean(train.Y) + np.std(train.Y), \"NOT HIGH GROWTH\", \"HIGH GROWTH\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train.drop(['growth', 'Y', 'postal_code', 'Years'], axis =1)\n",
    "y_train = train.growth\n",
    "x_test = test.drop(['growth', 'Y', 'postal_code', 'Years'], axis =1)\n",
    "y_test = test.growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifier_parameters = {}\n",
    "\n",
    "##### Random Forest classifier\n",
    "classifiers['Random Forest'] = Pipeline([('clf', RandomForestClassifier())])\n",
    "classifier_parameters['Random Forest'] = {'clf__max_depth':(1, 3, 9, 12, 15), 'clf__class_weight': (None, \"balanced\", \"balanced_subsample\")}\n",
    "\n",
    "##### AdaBoost classifier\n",
    "classifiers['AdaBoost'] = Pipeline([('clf', AdaBoostClassifier())])\n",
    "classifier_parameters['AdaBoost'] = {'clf__n_estimators':(30, 40, 50, 60, 70)}\n",
    "\n",
    "##### SVM\n",
    "# classifiers['SVM'] = Pipeline([('clf', SVC())])\n",
    "# classifier_parameters['SVM'] = {'clf__C':(0.01, 0.1, 1, 10), 'clf__kernel': ('poly', 'rbf', 'sigmoid'), 'clf__degree': (2,3), 'clf__gamma': (0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1)}\n",
    "\n",
    "#### Neural Networks\n",
    "classifiers['NN'] = Pipeline([('clf', MLPClassifier(activation='logistic'))])\n",
    "classifier_parameters['NN'] = {'clf__hidden_layer_sizes':((10,15,10), (15))}\n",
    "\n",
    "#### kNN\n",
    "classifiers['kNN'] = Pipeline([('clf', neighbors.KNeighborsClassifier())])\n",
    "classifier_parameters['kNN'] = {'clf__n_neighbors':(3,5,7), 'clf__weights': ('uniform', 'distance')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Algorithm - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: kNN\n",
      "Fold 1: Random Forest\n",
      "Fold 1: NN\n",
      "Fold 1: AdaBoost\n",
      "Fold 2: kNN\n",
      "Fold 2: Random Forest\n",
      "Fold 2: NN\n",
      "Fold 2: AdaBoost\n",
      "Fold 3: kNN\n",
      "Fold 3: Random Forest\n",
      "Fold 3: NN\n",
      "Fold 3: AdaBoost\n",
      "Fold 4: kNN\n",
      "Fold 4: Random Forest\n",
      "Fold 4: NN\n",
      "Fold 4: AdaBoost\n",
      "Fold 5: kNN\n",
      "Fold 5: Random Forest\n",
      "Fold 5: NN\n",
      "Fold 5: AdaBoost\n",
      "Fold 6: kNN\n",
      "Fold 6: Random Forest\n",
      "Fold 6: NN\n",
      "Fold 6: AdaBoost\n",
      "Fold 7: kNN\n",
      "Fold 7: Random Forest\n",
      "Fold 7: NN\n",
      "Fold 7: AdaBoost\n",
      "Fold 8: kNN\n",
      "Fold 8: Random Forest\n",
      "Fold 8: NN\n",
      "Fold 8: AdaBoost\n",
      "Fold 9: kNN\n",
      "Fold 9: Random Forest\n",
      "Fold 9: NN\n",
      "Fold 9: AdaBoost\n",
      "Fold 10: kNN\n",
      "Fold 10: Random Forest\n",
      "Fold 10: NN\n",
      "Fold 10: AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder to transform output labels.\n",
    "le = LabelEncoder() \n",
    "\n",
    "# Split features and class into two dataframes.\n",
    "X_training = x_train.values\n",
    "y_training = le.fit_transform(y_train.values)\n",
    "\n",
    "# Initialize scores dictionary\n",
    "scores = pd.DataFrame(columns=['fold', 'algorithm', 'parameters', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score'])\n",
    "\n",
    "# 10 fold CV\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Outer Cross Validation\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X_training):\n",
    "    X_train, X_test = X_training[train_index], X_training[test_index]\n",
    "    Y_train, Y_test = y_training[train_index], y_training[test_index]\n",
    "    \n",
    "    fold = fold + 1\n",
    "\n",
    "    # Inner CV\n",
    "    for name, clf in classifiers.items():\n",
    "        print('Fold ' + str(fold) + ': ' + name)\n",
    "        if name in classifier_parameters:\n",
    "            gs = GridSearchCV(estimator=clf, param_grid=classifier_parameters[name])\n",
    "            gs.fit(X_train, Y_train)\n",
    "            y_pred = gs.predict(X_test)\n",
    "            best_params = str(gs.best_params_)\n",
    "        else:\n",
    "            clf.fit(X_train, Y_train)\n",
    "            y_pred = clf.predict(Y_test)\n",
    "            best_params = 'default'\n",
    "        \n",
    "        # collect the scores for printing out later\n",
    "        scores = scores.append(pd.DataFrame(data={'fold':[fold],\n",
    "                                                  'algorithm':[name], \n",
    "                                                  'parameters':[best_params], \n",
    "                                                  'accuracy':[accuracy_score(Y_test, y_pred)], \n",
    "                                                  'precision':[precision_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'recall':[recall_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'kappa':[cohen_kappa_score(Y_test, y_pred)],\n",
    "                                                  'f1_score':[f1_score(Y_test, y_pred, average='weighted')]}), \n",
    "                               ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.621187</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.124495</td>\n",
       "      <td>0.644190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.560962</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.582807</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.673440</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.184442</td>\n",
       "      <td>0.683984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision    recall     kappa  f1_score\n",
       "algorithm                                                       \n",
       "AdaBoost       0.673913   0.621187  0.673913  0.124495  0.644190\n",
       "NN             0.728261   0.560962  0.728261  0.000000  0.623161\n",
       "Random Forest  0.739130   0.582807  0.739130  0.000000  0.629175\n",
       "kNN            0.739130   0.673440  0.739130  0.184442  0.683984"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score']].groupby(['algorithm']).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 2 labels evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.633913</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.259467</td>\n",
       "      <td>0.630785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.682876</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.299433</td>\n",
       "      <td>0.650687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.645236</td>\n",
       "      <td>0.663826</td>\n",
       "      <td>0.645236</td>\n",
       "      <td>0.289776</td>\n",
       "      <td>0.647545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.643163</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.277887</td>\n",
       "      <td>0.639561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision    recall     kappa  f1_score\n",
       "algorithm                                                       \n",
       "AdaBoost       0.630435   0.633913  0.630435  0.259467  0.630785\n",
       "NN             0.663043   0.682876  0.663043  0.299433  0.650687\n",
       "Random Forest  0.645236   0.663826  0.645236  0.289776  0.647545\n",
       "kNN            0.641304   0.643163  0.641304  0.277887  0.639561"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score']].groupby(['algorithm']).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 categories high/not high growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.847597</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.270240</td>\n",
       "      <td>0.851709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.756144</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.855717</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.253338</td>\n",
       "      <td>0.847872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.858928</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.256016</td>\n",
       "      <td>0.841023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision    recall     kappa  f1_score\n",
       "algorithm                                                       \n",
       "AdaBoost       0.847826   0.847597  0.847826  0.270240  0.851709\n",
       "NN             0.869565   0.756144  0.869565  0.000000  0.808898\n",
       "Random Forest  0.880435   0.855717  0.880435  0.253338  0.847872\n",
       "kNN            0.836957   0.858928  0.836957  0.256016  0.841023"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score']].groupby(['algorithm']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.772313</td>\n",
       "      <td>{'clf__n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.767589</td>\n",
       "      <td>{'clf__n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.925092</td>\n",
       "      <td>{'clf__n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.898429</td>\n",
       "      <td>{'clf__n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.810817</td>\n",
       "      <td>{'clf__n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.868248</td>\n",
       "      <td>{'clf__n_estimators': 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.870438</td>\n",
       "      <td>{'clf__n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.840289</td>\n",
       "      <td>{'clf__n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.863129</td>\n",
       "      <td>{'clf__n_estimators': 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.795546</td>\n",
       "      <td>{'clf__n_estimators': 30}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm  f1_score                 parameters\n",
       "3   AdaBoost  0.772313  {'clf__n_estimators': 30}\n",
       "7   AdaBoost  0.767589  {'clf__n_estimators': 30}\n",
       "11  AdaBoost  0.925092  {'clf__n_estimators': 40}\n",
       "15  AdaBoost  0.898429  {'clf__n_estimators': 30}\n",
       "19  AdaBoost  0.810817  {'clf__n_estimators': 30}\n",
       "23  AdaBoost  0.868248  {'clf__n_estimators': 70}\n",
       "27  AdaBoost  0.870438  {'clf__n_estimators': 30}\n",
       "31  AdaBoost  0.840289  {'clf__n_estimators': 30}\n",
       "35  AdaBoost  0.863129  {'clf__n_estimators': 50}\n",
       "39  AdaBoost  0.795546  {'clf__n_estimators': 30}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'f1_score', 'parameters']][scores['algorithm']=='AdaBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=30, random_state=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder() \n",
    "\n",
    "# Split features and class into two dataframes.\n",
    "X_training = x_train.values\n",
    "y_training = le.fit_transform(y_train.values)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=30)\n",
    "clf.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_test_le = le.fit_transform(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0 23]\n",
      " [53  0 54]\n",
      " [ 0  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.65      0.53        65\n",
      "          1       0.00      0.00      0.00       107\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.17      0.24      0.20       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_le, y_pred))\n",
    "print(classification_report(y_test_le, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifier_parameters = {}\n",
    "\n",
    "kernels = ('poly','rbf','cosine')\n",
    "kernel_gamma = (0.01, 0.25, 0.5, 0.75)\n",
    "kernel_ncomponents = (2,5,10)\n",
    "kernel_degree = (2,3)\n",
    "\n",
    "##### Random Forest classifier\n",
    "classifiers['Random Forest'] = Pipeline([('kpca',KernelPCA()),('clf', RandomForestClassifier())])\n",
    "classifier_parameters['Random Forest'] = {'clf__max_depth':(1, 3, 9, 12, 15), 'clf__class_weight': (None, \"balanced\", \"balanced_subsample\"), 'kpca__kernel' : kernels, 'kpca__n_components' :kernel_ncomponents, 'kpca__degree' : kernel_degree, 'kpca__gamma': kernel_gamma}\n",
    "\n",
    "##### AdaBoost classifier\n",
    "classifiers['AdaBoost'] = Pipeline([('kpca',KernelPCA()), ('clf', AdaBoostClassifier())])\n",
    "classifier_parameters['AdaBoost'] = {'clf__n_estimators':(30, 40, 50, 60, 70), 'kpca__kernel' : kernels, 'kpca__n_components' : kernel_ncomponents, 'kpca__degree' : kernel_degree, 'kpca__gamma': kernel_gamma}\n",
    "\n",
    "##### SVM\n",
    "# classifiers['SVM'] = Pipeline([('clf', SVC())])\n",
    "# classifier_parameters['SVM'] = {'clf__C':(0.01, 0.1, 1, 10), 'clf__kernel': ('poly', 'rbf', 'sigmoid'), 'clf__degree': (2,3), 'clf__gamma': (0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1)}\n",
    "\n",
    "#### Neural Networks\n",
    "classifiers['NN'] = Pipeline([('kpca',KernelPCA()), ('clf', MLPClassifier(activation='logistic'))])\n",
    "classifier_parameters['NN'] = {'clf__hidden_layer_sizes':((10,15,10), (15)),'kpca__kernel':kernels, 'kpca__n_components':kernel_ncomponents, 'kpca__degree':kernel_degree, 'kpca__gamma': kernel_gamma}\n",
    "\n",
    "#### kNN\n",
    "classifiers['kNN'] = Pipeline([('kpca',KernelPCA()), ('clf', neighbors.KNeighborsClassifier())])\n",
    "classifier_parameters['kNN'] = {'clf__n_neighbors':(3,5,7), 'clf__weights': ('uniform', 'distance'), 'kpca__kernel':kernels, 'kpca__n_components': kernel_ncomponents, 'kpca__degree': kernel_degree, 'kpca__gamma': kernel_gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: kNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamiediner/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jamiediner/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Random Forest\n",
      "Fold 1: NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamiediner/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: AdaBoost\n",
      "Fold 2: kNN\n",
      "Fold 2: Random Forest\n",
      "Fold 2: NN\n",
      "Fold 2: AdaBoost\n",
      "Fold 3: kNN\n",
      "Fold 3: Random Forest\n",
      "Fold 3: NN\n",
      "Fold 3: AdaBoost\n",
      "Fold 4: kNN\n",
      "Fold 4: Random Forest\n",
      "Fold 4: NN\n",
      "Fold 4: AdaBoost\n",
      "Fold 5: kNN\n",
      "Fold 5: Random Forest\n",
      "Fold 5: NN\n",
      "Fold 5: AdaBoost\n",
      "Fold 6: kNN\n",
      "Fold 6: Random Forest\n",
      "Fold 6: NN\n",
      "Fold 6: AdaBoost\n",
      "Fold 7: kNN\n",
      "Fold 7: Random Forest\n",
      "Fold 7: NN\n",
      "Fold 7: AdaBoost\n",
      "Fold 8: kNN\n",
      "Fold 8: Random Forest\n",
      "Fold 8: NN\n",
      "Fold 8: AdaBoost\n",
      "Fold 9: kNN\n",
      "Fold 9: Random Forest\n",
      "Fold 9: NN\n",
      "Fold 9: AdaBoost\n",
      "Fold 10: kNN\n",
      "Fold 10: Random Forest\n",
      "Fold 10: NN\n",
      "Fold 10: AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder to transform output labels.\n",
    "le = LabelEncoder() \n",
    "\n",
    "# Split features and class into two dataframes.\n",
    "X_training = x_train.values\n",
    "y_training = le.fit_transform(y_train.values)\n",
    "\n",
    "# Initialize scores dictionary\n",
    "scores = pd.DataFrame(columns=['fold', 'algorithm', 'parameters', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score'])\n",
    "\n",
    "# 10 fold CV\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Outer Cross Validation\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X_training):\n",
    "    X_train, X_test = X_training[train_index], X_training[test_index]\n",
    "    Y_train, Y_test = y_training[train_index], y_training[test_index]\n",
    "    \n",
    "    fold = fold + 1\n",
    "\n",
    "    # Inner CV\n",
    "    for name, clf in classifiers.items():\n",
    "        print('Fold ' + str(fold) + ': ' + name)\n",
    "        if name in classifier_parameters:\n",
    "            gs = GridSearchCV(estimator=clf, param_grid=classifier_parameters[name])\n",
    "            gs.fit(X_train, Y_train)\n",
    "            y_pred = gs.predict(X_test)\n",
    "            best_params = str(gs.best_params_)\n",
    "        else:\n",
    "            clf.fit(X_train, Y_train)\n",
    "            y_pred = clf.predict(Y_test)\n",
    "            best_params = 'default'\n",
    "        \n",
    "        # collect the scores for printing out later\n",
    "        scores = scores.append(pd.DataFrame(data={'fold':[fold],\n",
    "                                                  'algorithm':[name], \n",
    "                                                  'parameters':[best_params], \n",
    "                                                  'accuracy':[accuracy_score(Y_test, y_pred)], \n",
    "                                                  'precision':[precision_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'recall':[recall_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'kappa':[cohen_kappa_score(Y_test, y_pred)],\n",
    "                                                  'f1_score':[f1_score(Y_test, y_pred, average='weighted')]}), \n",
    "                               ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.560597</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.553825</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.605240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.621820</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.646205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.565927</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision    recall     kappa  f1_score\n",
       "algorithm                                                       \n",
       "AdaBoost       0.728261   0.560597  0.728261  0.000000  0.628261\n",
       "NN             0.717391   0.553825  0.717391  0.002882  0.605240\n",
       "Random Forest  0.739130   0.621820  0.739130  0.098446  0.646205\n",
       "kNN            0.695652   0.565927  0.695652  0.000000  0.620902"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score']].groupby(['algorithm']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ \"{'kpca__kernel': 'poly', 'kpca__gamma': 0.25, 'clf__max_depth': 1, 'kpca__degree': 3, 'kpca__n_components': 2, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'poly', 'kpca__gamma': 0.25, 'clf__max_depth': 3, 'kpca__degree': 3, 'kpca__n_components': 5, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'poly', 'kpca__gamma': 0.75, 'clf__max_depth': 1, 'kpca__degree': 2, 'kpca__n_components': 10, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'poly', 'kpca__gamma': 0.01, 'clf__max_depth': 3, 'kpca__degree': 3, 'kpca__n_components': 5, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'poly', 'kpca__gamma': 0.01, 'clf__max_depth': 1, 'kpca__degree': 3, 'kpca__n_components': 2, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'poly', 'kpca__gamma': 0.01, 'clf__max_depth': 3, 'kpca__degree': 2, 'kpca__n_components': 2, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'cosine', 'kpca__gamma': 0.01, 'clf__max_depth': 3, 'kpca__degree': 3, 'kpca__n_components': 5, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'cosine', 'kpca__gamma': 0.25, 'clf__max_depth': 3, 'kpca__degree': 2, 'kpca__n_components': 2, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'cosine', 'kpca__gamma': 0.01, 'clf__max_depth': 3, 'kpca__degree': 3, 'kpca__n_components': 10, 'clf__class_weight': None}\",\n",
       "       \"{'kpca__kernel': 'poly', 'kpca__gamma': 0.25, 'clf__max_depth': 3, 'kpca__degree': 2, 'kpca__n_components': 5, 'clf__class_weight': None}\"], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'f1_score', 'parameters']][scores['algorithm']=='Random Forest'].parameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training_kpca = KernelPCA(gamma = 0.01, degree=3, n_components=10).fit_transform(X_training)\n",
    "clf = RandomForestClassifier(max_depth=3, class_weight=None)\n",
    "clf.fit(X_training_kpca, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9   0  56]\n",
      " [  4   0 103]\n",
      " [  0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.14      0.23        65\n",
      "          1       0.00      0.00      0.00       107\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.26      0.05      0.09       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_kpca = KernelPCA(gamma = 0.01, degree=3, n_components=10).fit_transform(x_test)\n",
    "y_pred = clf.predict(X_test_kpca)\n",
    "y_test_le = le.fit_transform(y_test.values)\n",
    "print(confusion_matrix(y_test_le, y_pred))\n",
    "print(classification_report(y_test_le, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "x_train_os, y_train_os = ros.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifier_parameters = {}\n",
    "\n",
    "##### Random Forest classifier\n",
    "classifiers['Random Forest'] = Pipeline([('clf', RandomForestClassifier())])\n",
    "classifier_parameters['Random Forest'] = {'clf__max_depth':(1, 3, 9, 12, 15), 'clf__class_weight': (None, \"balanced\", \"balanced_subsample\")}\n",
    "\n",
    "##### AdaBoost classifier\n",
    "classifiers['AdaBoost'] = Pipeline([('clf', AdaBoostClassifier())])\n",
    "classifier_parameters['AdaBoost'] = {'clf__n_estimators':(30, 40, 50, 60, 70)}\n",
    "\n",
    "##### SVM\n",
    "# classifiers['SVM'] = Pipeline([('clf', SVC())])\n",
    "# classifier_parameters['SVM'] = {'clf__C':(0.01, 0.1, 1, 10), 'clf__kernel': ('poly', 'rbf', 'sigmoid'), 'clf__degree': (2,3), 'clf__gamma': (0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1)}\n",
    "\n",
    "#### Neural Networks\n",
    "classifiers['NN'] = Pipeline([('clf', MLPClassifier(activation='logistic'))])\n",
    "classifier_parameters['NN'] = {'clf__hidden_layer_sizes':((10,15,10), (15))}\n",
    "\n",
    "#### kNN\n",
    "classifiers['kNN'] = Pipeline([('clf', neighbors.KNeighborsClassifier())])\n",
    "classifier_parameters['kNN'] = {'clf__n_neighbors':(3,5,7), 'clf__weights': ('uniform', 'distance')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: kNN\n",
      "Fold 1: Random Forest\n",
      "Fold 1: NN\n",
      "Fold 1: AdaBoost\n",
      "Fold 2: kNN\n",
      "Fold 2: Random Forest\n",
      "Fold 2: NN\n",
      "Fold 2: AdaBoost\n",
      "Fold 3: kNN\n",
      "Fold 3: Random Forest\n",
      "Fold 3: NN\n",
      "Fold 3: AdaBoost\n",
      "Fold 4: kNN\n",
      "Fold 4: Random Forest\n",
      "Fold 4: NN\n",
      "Fold 4: AdaBoost\n",
      "Fold 5: kNN\n",
      "Fold 5: Random Forest\n",
      "Fold 5: NN\n",
      "Fold 5: AdaBoost\n",
      "Fold 6: kNN\n",
      "Fold 6: Random Forest\n",
      "Fold 6: NN\n",
      "Fold 6: AdaBoost\n",
      "Fold 7: kNN\n",
      "Fold 7: Random Forest\n",
      "Fold 7: NN\n",
      "Fold 7: AdaBoost\n",
      "Fold 8: kNN\n",
      "Fold 8: Random Forest\n",
      "Fold 8: NN\n",
      "Fold 8: AdaBoost\n",
      "Fold 9: kNN\n",
      "Fold 9: Random Forest\n",
      "Fold 9: NN\n",
      "Fold 9: AdaBoost\n",
      "Fold 10: kNN\n",
      "Fold 10: Random Forest\n",
      "Fold 10: NN\n",
      "Fold 10: AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder to transform output labels.\n",
    "le = LabelEncoder() \n",
    "\n",
    "# Split features and class into two dataframes.\n",
    "X_training = x_train_os\n",
    "y_training = le.fit_transform(y_train_os)\n",
    "\n",
    "# Initialize scores dictionary\n",
    "scores = pd.DataFrame(columns=['fold', 'algorithm', 'parameters', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score'])\n",
    "\n",
    "# 10 fold CV\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Outer Cross Validation\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X_training):\n",
    "    X_train, X_test = X_training[train_index], X_training[test_index]\n",
    "    Y_train, Y_test = y_training[train_index], y_training[test_index]\n",
    "    \n",
    "    fold = fold + 1\n",
    "\n",
    "    # Inner CV\n",
    "    for name, clf in classifiers.items():\n",
    "        print('Fold ' + str(fold) + ': ' + name)\n",
    "        if name in classifier_parameters:\n",
    "            gs = GridSearchCV(estimator=clf, param_grid=classifier_parameters[name])\n",
    "            gs.fit(X_train, Y_train)\n",
    "            y_pred = gs.predict(X_test)\n",
    "            best_params = str(gs.best_params_)\n",
    "        else:\n",
    "            clf.fit(X_train, Y_train)\n",
    "            y_pred = clf.predict(Y_test)\n",
    "            best_params = 'default'\n",
    "        \n",
    "        # collect the scores for printing out later\n",
    "        scores = scores.append(pd.DataFrame(data={'fold':[fold],\n",
    "                                                  'algorithm':[name], \n",
    "                                                  'parameters':[best_params], \n",
    "                                                  'accuracy':[accuracy_score(Y_test, y_pred)], \n",
    "                                                  'precision':[precision_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'recall':[recall_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'kappa':[cohen_kappa_score(Y_test, y_pred)],\n",
    "                                                  'f1_score':[f1_score(Y_test, y_pred, average='weighted')]}), \n",
    "                               ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.739723</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.521611</td>\n",
       "      <td>0.685917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.616856</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.410964</td>\n",
       "      <td>0.605398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.930396</td>\n",
       "      <td>0.937475</td>\n",
       "      <td>0.930396</td>\n",
       "      <td>0.895137</td>\n",
       "      <td>0.929023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.888406</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.789608</td>\n",
       "      <td>0.849070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision    recall     kappa  f1_score\n",
       "algorithm                                                       \n",
       "AdaBoost       0.680000   0.739723  0.680000  0.521611  0.685917\n",
       "NN             0.610000   0.616856  0.610000  0.410964  0.605398\n",
       "Random Forest  0.930396   0.937475  0.930396  0.895137  0.929023\n",
       "kNN            0.865000   0.888406  0.865000  0.789608  0.849070"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score']].groupby(['algorithm']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"{'clf__max_depth': 12, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 15, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': 'balanced_subsample'}\",\n",
       "       \"{'clf__max_depth': 15, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 9, 'clf__class_weight': 'balanced_subsample'}\",\n",
       "       \"{'clf__max_depth': 15, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 15, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': 'balanced'}\"], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'f1_score', 'parameters']][scores['algorithm']=='Random Forest'].parameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_training = x_train_os\n",
    "le = LabelEncoder() \n",
    "y_training = le.fit_transform(y_train_os)\n",
    "clf = RandomForestClassifier(max_depth=12, class_weight=None)\n",
    "clf.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0 50]\n",
      " [19  0 88]\n",
      " [ 0  0  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.23      0.30        65\n",
      "          1       0.00      0.00      0.00       107\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.17      0.09      0.11       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_test_le = le.fit_transform(y_test.values)\n",
    "print(confusion_matrix(y_test_le, y_pred))\n",
    "print(classification_report(y_test_le, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and testing randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../Data/Matrix_Apr10.xlsx\", sheetname='total')\n",
    "\n",
    "#3 classes\n",
    "#data['growth'] = np.where(data['Y'] <= np.mean(data.Y) - np.std(data.Y), \"NEGATIVE\", np.where(data['Y'] >= np.mean(data.Y) + np.std(data.Y), \"HIGH_GROWTH\", \"NORMAL_GROWTH\"))\n",
    "\n",
    "#2 classes high/nothigh\n",
    "data['growth'] = np.where(data['Y'] <= np.mean(data.Y) + np.std(data.Y), \"NOT HIGH GROWTH\", \"HIGH GROWTH\")\n",
    "\n",
    "X = data.drop(['growth', 'Y', 'postal_code', 'Years'], axis =1)\n",
    "Y = data.growth\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifier_parameters = {}\n",
    "\n",
    "##### Random Forest classifier\n",
    "classifiers['Random Forest'] = Pipeline([('clf', RandomForestClassifier())])\n",
    "classifier_parameters['Random Forest'] = {'clf__max_depth':(1, 3, 9, 12, 15), 'clf__class_weight': (None, \"balanced\", \"balanced_subsample\")}\n",
    "\n",
    "##### AdaBoost classifier\n",
    "classifiers['AdaBoost'] = Pipeline([('clf', AdaBoostClassifier())])\n",
    "classifier_parameters['AdaBoost'] = {'clf__n_estimators':(30, 40, 50, 60, 70)}\n",
    "\n",
    "##### SVM\n",
    "# classifiers['SVM'] = Pipeline([('clf', SVC())])\n",
    "# classifier_parameters['SVM'] = {'clf__C':(0.01, 0.1, 1, 10), 'clf__kernel': ('poly', 'rbf', 'sigmoid'), 'clf__degree': (2,3), 'clf__gamma': (0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1)}\n",
    "\n",
    "#### Neural Networks\n",
    "classifiers['NN'] = Pipeline([('clf', MLPClassifier(activation='logistic'))])\n",
    "classifier_parameters['NN'] = {'clf__hidden_layer_sizes':((10,15,10), (15))}\n",
    "\n",
    "#### kNN\n",
    "classifiers['kNN'] = Pipeline([('clf', neighbors.KNeighborsClassifier())])\n",
    "classifier_parameters['kNN'] = {'clf__n_neighbors':(3,5,7), 'clf__weights': ('uniform', 'distance')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: kNN\n",
      "Fold 1: Random Forest\n",
      "Fold 1: NN\n",
      "Fold 1: AdaBoost\n",
      "Fold 2: kNN\n",
      "Fold 2: Random Forest\n",
      "Fold 2: NN\n",
      "Fold 2: AdaBoost\n",
      "Fold 3: kNN\n",
      "Fold 3: Random Forest\n",
      "Fold 3: NN\n",
      "Fold 3: AdaBoost\n",
      "Fold 4: kNN\n",
      "Fold 4: Random Forest\n",
      "Fold 4: NN\n",
      "Fold 4: AdaBoost\n",
      "Fold 5: kNN\n",
      "Fold 5: Random Forest\n",
      "Fold 5: NN\n",
      "Fold 5: AdaBoost\n",
      "Fold 6: kNN\n",
      "Fold 6: Random Forest\n",
      "Fold 6: NN\n",
      "Fold 6: AdaBoost\n",
      "Fold 7: kNN\n",
      "Fold 7: Random Forest\n",
      "Fold 7: NN\n",
      "Fold 7: AdaBoost\n",
      "Fold 8: kNN\n",
      "Fold 8: Random Forest\n",
      "Fold 8: NN\n",
      "Fold 8: AdaBoost\n",
      "Fold 9: kNN\n",
      "Fold 9: Random Forest\n",
      "Fold 9: NN\n",
      "Fold 9: AdaBoost\n",
      "Fold 10: kNN\n",
      "Fold 10: Random Forest\n",
      "Fold 10: NN\n",
      "Fold 10: AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder to transform output labels.\n",
    "le = LabelEncoder() \n",
    "\n",
    "# Split features and class into two dataframes.\n",
    "X_training = x_train.values\n",
    "y_training = le.fit_transform(y_train.values)\n",
    "\n",
    "# Initialize scores dictionary\n",
    "scores = pd.DataFrame(columns=['fold', 'algorithm', 'parameters', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score'])\n",
    "\n",
    "# 10 fold CV\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Outer Cross Validation\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X_training):\n",
    "    X_train, X_test = X_training[train_index], X_training[test_index]\n",
    "    Y_train, Y_test = y_training[train_index], y_training[test_index]\n",
    "    \n",
    "    fold = fold + 1\n",
    "\n",
    "    # Inner CV\n",
    "    for name, clf in classifiers.items():\n",
    "        print('Fold ' + str(fold) + ': ' + name)\n",
    "        if name in classifier_parameters:\n",
    "            gs = GridSearchCV(estimator=clf, param_grid=classifier_parameters[name])\n",
    "            gs.fit(X_train, Y_train)\n",
    "            y_pred = gs.predict(X_test)\n",
    "            best_params = str(gs.best_params_)\n",
    "        else:\n",
    "            clf.fit(X_train, Y_train)\n",
    "            y_pred = clf.predict(Y_test)\n",
    "            best_params = 'default'\n",
    "        \n",
    "        # collect the scores for printing out later\n",
    "        scores = scores.append(pd.DataFrame(data={'fold':[fold],\n",
    "                                                  'algorithm':[name], \n",
    "                                                  'parameters':[best_params], \n",
    "                                                  'accuracy':[accuracy_score(Y_test, y_pred)], \n",
    "                                                  'precision':[precision_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'recall':[recall_score(Y_test, y_pred, average='weighted')],\n",
    "                                                  'kappa':[cohen_kappa_score(Y_test, y_pred)],\n",
    "                                                  'f1_score':[f1_score(Y_test, y_pred, average='weighted')]}), \n",
    "                               ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.876263</td>\n",
       "      <td>0.852288</td>\n",
       "      <td>0.876263</td>\n",
       "      <td>0.194062</td>\n",
       "      <td>0.862071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.785640</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.878016</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.314279</td>\n",
       "      <td>0.881491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.833946</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision    recall     kappa  f1_score\n",
       "algorithm                                                       \n",
       "AdaBoost       0.876263   0.852288  0.876263  0.194062  0.862071\n",
       "NN             0.886364   0.785640  0.886364  0.000000  0.832968\n",
       "Random Forest  0.897727   0.878016  0.897727  0.314279  0.881491\n",
       "kNN            0.886364   0.833946  0.886364  0.000000  0.840632"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'accuracy', 'precision', 'recall', 'kappa', 'f1_score']].groupby(['algorithm']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"{'clf__max_depth': 12, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 15, 'clf__class_weight': 'balanced_subsample'}\",\n",
       "       \"{'clf__max_depth': 15, 'clf__class_weight': 'balanced_subsample'}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': 'balanced'}\",\n",
       "       \"{'clf__max_depth': 9, 'clf__class_weight': 'balanced'}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': 'balanced_subsample'}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': None}\",\n",
       "       \"{'clf__max_depth': 9, 'clf__class_weight': 'balanced'}\",\n",
       "       \"{'clf__max_depth': 12, 'clf__class_weight': 'balanced_subsample'}\"], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[['algorithm', 'f1_score', 'parameters']][scores['algorithm']=='Random Forest'].parameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5  25]\n",
      " [  2 158]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.17      0.27        30\n",
      "          1       0.86      0.99      0.92       160\n",
      "\n",
      "avg / total       0.84      0.86      0.82       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_training = x_train.values\n",
    "y_training = le.fit_transform(y_train.values)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=12, class_weight='balanced_subsample')\n",
    "clf.fit(X_training, y_training)\n",
    "y_pred = clf.predict(x_test)\n",
    "y_test_le = le.fit_transform(y_test.values)\n",
    "print(confusion_matrix(y_test_le, y_pred))\n",
    "print(classification_report(y_test_le, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HIGH_GROWTH', 'NORMAL_GROWTH'], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
